{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qdisb831 because the default path (/home/uoezdemir/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import skimage.transform as st\n",
    "from torchmetrics import Accuracy, CohenKappa, F1Score, JaccardIndex, Precision, Recall\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "from interaction_exploration.config import get_config\n",
    "from interaction_exploration.run import get_trainer\n",
    "from interaction_exploration.trainer import *\n",
    "from interaction_exploration.models.policy import * \n",
    "\n",
    "from rl.common.utils import logger\n",
    "from rl.common.env_utils import construct_envs, get_env_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_affordance(last_event, size=(2, 128, 128)):\n",
    "    affordance_types = [['pickupable'], ['moveable', 'pickupable']]\n",
    "\n",
    "    gt_affordances = np.zeros((2, 300, 300), dtype=np.float32)\n",
    "    for obj in last_event.metadata[\"objects\"]:\n",
    "        if obj[\"objectId\"] not in last_event.instance_masks:\n",
    "            continue\n",
    "        # Extract Object Instance Mask\n",
    "        obj_instance_seg = last_event.instance_masks[obj[\"objectId\"]]\n",
    "        # Extrach GT Object Affordances\n",
    "        obj_gt_affordance = np.array(\n",
    "            [np.any([obj[a] for a in aff]) for aff in affordance_types]\n",
    "        )\n",
    "        # Write Object Affordance into the Affordance Map\n",
    "        gt_affordances[:, obj_instance_seg] = obj_gt_affordance[:, None].astype(\n",
    "            np.float32\n",
    "        )\n",
    "    \n",
    "    if size:\n",
    "        gt_affordances = st.resize(gt_affordances, size, order=0, preserve_range=True, anti_aliasing=False)\n",
    "    \n",
    "    return gt_affordances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_affordance_evaluation_metrics(last_event, estimation, scores=None, _threshold = 0, _affordance_types = ['pickupable', 'moveable_pickupable'], size = (128, 128)):\n",
    "\n",
    "    metrics = {\n",
    "        \"IoU\": JaccardIndex(2),\n",
    "        \"accuracy\": Accuracy(2),\n",
    "        \"cohen_kappa\": CohenKappa(2),\n",
    "        \"precision\": Precision(),\n",
    "        \"recall\": Recall(),\n",
    "        \"f1_score\": F1Score(),\n",
    "        \"true_positive\": lambda est, gt: torch.sum(\n",
    "            torch.logical_and(est > _threshold, gt.type(torch.bool))\n",
    "        ),\n",
    "        \"true_negative\": lambda est, gt: torch.sum(\n",
    "            torch.logical_and(est < _threshold, gt.type(torch.bool))\n",
    "        ),\n",
    "        \"false_positive\": lambda est, gt: torch.sum(\n",
    "            torch.logical_and(est > _threshold, gt.type(torch.bool))\n",
    "        ),\n",
    "        \"false_negative\": lambda est, gt: torch.sum(\n",
    "            torch.logical_and(est < _threshold, gt.type(torch.bool))\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    ground_truth = get_gt_affordance(last_event)\n",
    "    if scores == None:\n",
    "        scores = {\n",
    "            affordance_type: {m: [] for m in metrics}\n",
    "            for affordance_type in _affordance_types\n",
    "        }\n",
    "        for affordance_type in _affordance_types:\n",
    "            scores[affordance_type][\"object_level_accuracy\"] = []\n",
    "\n",
    "    for m in metrics:\n",
    "        for est, gt, affordance_type in zip(\n",
    "            estimation, ground_truth, _affordance_types\n",
    "        ):\n",
    "            result = metrics[m](torch.from_numpy(est.cpu().numpy()), torch.from_numpy(gt).type(torch.int32)).item()\n",
    "            if np.isfinite(result):\n",
    "                scores[affordance_type][m].append(result)\n",
    "\n",
    "    estimation_npy = (estimation.cpu().numpy() > _threshold).astype(int)\n",
    "    ground_truth_npy = ground_truth.astype(int)\n",
    "    gt_segmentation = last_event.instance_masks\n",
    "\n",
    "    for est, gt, affordance_type in zip(estimation_npy, ground_truth_npy, _affordance_types):\n",
    "        accuracies = []\n",
    "        for class_ in gt_segmentation:\n",
    "            if size:\n",
    "                gt_segmentation_ = st.resize(gt_segmentation[class_], size, order=0, preserve_range=True, anti_aliasing=False)\n",
    "                if gt_segmentation_.sum() == 0:\n",
    "                    continue\n",
    "            est_class = Counter(est[gt_segmentation_].flatten()).most_common(1)[0][0]\n",
    "            gt_class = Counter(gt[gt_segmentation_].flatten()).most_common(1)[0][0]\n",
    "            accuracies.append(float(gt_class == est_class))\n",
    "        scores[affordance_type]['object_level_accuracy'].append(np.mean(accuracies))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_single_episode(trainer, ppo_cfg, batch, current_episode_reward, test_recurrent_hidden_states, prev_actions, not_done_masks, stats_episodes):\n",
    "    infos = None\n",
    "    affordance_scores = [None for _ in range(trainer.envs.num_envs)]\n",
    "    for step in range(ppo_cfg.num_steps):\n",
    "        # Apply Action\n",
    "        current_episodes = trainer.envs.current_episodes()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            (\n",
    "                _,\n",
    "                actions,\n",
    "                _,\n",
    "                test_recurrent_hidden_states,\n",
    "            ) = trainer.actor_critic.act(\n",
    "                batch,\n",
    "                test_recurrent_hidden_states,\n",
    "                prev_actions,\n",
    "                not_done_masks,\n",
    "                deterministic=False,\n",
    "            )\n",
    "\n",
    "            prev_actions.copy_(actions)\n",
    "\n",
    "        outputs = trainer.envs.step([a[0].item() for a in actions])\n",
    "\n",
    "        # Log Metrics\n",
    "        observations, rewards, dones, infos = [\n",
    "            list(x) for x in zip(*outputs)\n",
    "        ]\n",
    "        batch = trainer.batch_obs(observations, trainer.device)\n",
    "\n",
    "        for i in range(trainer.envs.num_envs):\n",
    "            last_event = trainer.envs.call_at(i, 'last_event')\n",
    "            affordance_scores[i] = calculate_affordance_evaluation_metrics(last_event, batch['aux'][i], affordance_scores[i])\n",
    "\n",
    "        not_done_masks = torch.tensor(\n",
    "            [[0.0] if done else [1.0] for done in dones],\n",
    "            dtype=torch.float,\n",
    "            device=trainer.device,\n",
    "        )\n",
    "\n",
    "        rewards = torch.tensor(\n",
    "            rewards, dtype=torch.float, device=trainer.device\n",
    "        ).unsqueeze(1)\n",
    "        current_episode_reward += rewards\n",
    "        n_envs = trainer.envs.num_envs\n",
    "        for i in range(n_envs):\n",
    "            # episode ended\n",
    "            if not_done_masks[i].item() == 0:\n",
    "                episode_stats = dict()\n",
    "                episode_stats[\"reward\"] = current_episode_reward[i].item()\n",
    "                episode_stats.update(\n",
    "                    trainer._extract_scalars_from_info(infos[i])\n",
    "                )\n",
    "                for affordance in affordance_scores[i]:\n",
    "                    for m in affordance_scores[i][affordance]:\n",
    "                        episode_stats[f\"{affordance}_{m}\"] = np.mean(affordance_scores[i][affordance][m])\n",
    "                current_episode_reward[i] = 0\n",
    "                stats_episodes[\n",
    "                    (\n",
    "                        current_episodes[i]['scene_id'],\n",
    "                        current_episodes[i]['episode_id'],\n",
    "                    )\n",
    "                ] = episode_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_evaluation(trainer, ppo_cfg, num_episodes):\n",
    "    stats_episodes = dict()\n",
    "\n",
    "    for _ in tqdm(range(num_episodes)):\n",
    "        observations = trainer.envs.reset()\n",
    "        batch = trainer.batch_obs(observations, trainer.device)\n",
    "\n",
    "        current_episode_reward = torch.zeros(\n",
    "            trainer.envs.num_envs, 1, device=trainer.device\n",
    "        )\n",
    "\n",
    "        test_recurrent_hidden_states = torch.zeros(\n",
    "            trainer.actor_critic.net.num_recurrent_layers,\n",
    "            trainer.config.NUM_PROCESSES,\n",
    "            ppo_cfg.hidden_size,\n",
    "            device=trainer.device,\n",
    "        )\n",
    "        prev_actions = torch.zeros(\n",
    "            trainer.config.NUM_PROCESSES, 1, device=trainer.device, dtype=torch.long\n",
    "        )\n",
    "        not_done_masks = torch.zeros(\n",
    "            trainer.config.NUM_PROCESSES, 1, device=trainer.device\n",
    "        )\n",
    "        trainer.actor_critic.eval()\n",
    "\n",
    "        execute_single_episode(\n",
    "            trainer,\n",
    "            ppo_cfg,\n",
    "            batch, \n",
    "            current_episode_reward, \n",
    "            test_recurrent_hidden_states, \n",
    "            prev_actions, \n",
    "            not_done_masks, \n",
    "            stats_episodes\n",
    "        )\n",
    "\n",
    "    # Log info so far\n",
    "    num_episodes = len(stats_episodes)\n",
    "    aggregated_stats = dict()\n",
    "    for stat_key in next(iter(stats_episodes.values())).keys():\n",
    "        aggregated_stats[stat_key] = {\n",
    "            'mean': (\n",
    "                sum([v[stat_key] for v in stats_episodes.values()])\n",
    "                / num_episodes\n",
    "            ),\n",
    "            'std': np.std([v[stat_key] for v in stats_episodes.values()])\n",
    "        }\n",
    "    for k, v in aggregated_stats.items():\n",
    "        logger.info(f\"Average episode {k}: {v['mean']:.4f} ({num_episodes} episodes)\")\n",
    "        logger.info(f\"episode {k} Std: {v['std']:.4f} ({num_episodes} episodes)\")\n",
    "\n",
    "    return aggregated_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config({'SEED': 1, 'NUM_PROCESSES': 2, 'X_DISPLAY': ':0', 'DEBUG': False, 'CUDA': True, 'CUDA_DETERMINISTIC': False, 'TORCH_GPU_ID': 0, 'CHECKPOINT_INTERVAL': 10, 'CHECKPOINT_FOLDER': 'models/eval', 'EVAL_CKPT_NUMBER': -1, 'LOG_FILE': 'models/eval/run.log', 'LOG_INTERVAL': 1, 'TENSORBOARD_DIR': 'models/eval/tb/', 'MODE': 'train', 'LOAD': 'models/ckpt.48.pth', 'DATA': Config({'AUX_MEAN': 0.04, 'AUX_STD': 0.06}), 'TASK_CONFIG': Config({'TASK': None}), 'OUT_DIR': '', 'EVAL': Config({'DATASET': 'interaction_exploration/data/test_episodes_K_16.json'}), 'MODEL': Config({'TRAINER': 'BeaconTrainer', 'ENCODER': 'RGBAffordanceTwoStream', 'BEACON_MODEL': 'models/epoch=04-val_loss=0.4979.ckpt'}), 'ENV': Config({'NUM_ENV_STEPS': 1000000, 'NUM_STEPS': 256, 'ENV_NAME': 'ThorInteractionCountComparison-v0', 'LOCAL_EXE': None, 'OBS_SZ': 128, 'ROT_SIZE_X': 15, 'ROT_SIZE_Y': 30, 'FRAME_SIZE': 300, 'NGRID': 5}), 'RL': Config({'PPO': Config({'clip_param': 0.2, 'ppo_epoch': 4, 'num_mini_batch': 2, 'value_loss_coef': 0.5, 'entropy_coef': 0.01, 'lr': 0.0002, 'eps': 1e-05, 'max_grad_norm': 0.5, 'num_steps': 256, 'use_gae': True, 'use_linear_lr_decay': False, 'use_linear_clip_decay': False, 'gamma': 0.99, 'tau': 0.95, 'reward_window_size': 10, 'use_normalized_advantage': False, 'gae_lambda': 0.95, 'hidden_size': 512, 'policy_wts': ''})}), 'NUM_UPDATES': 1953})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = 'interaction_exploration/config/intexp.yaml'\n",
    "options = [\n",
    "    'ENV.NUM_STEPS', '256',\n",
    "    'NUM_PROCESSES', '2',\n",
    "    'EVAL.DATASET', 'interaction_exploration/data/test_episodes_K_16.json',\n",
    "    'TORCH_GPU_ID', '0',\n",
    "    'X_DISPLAY', ':0',\n",
    "    'CHECKPOINT_FOLDER', 'models/eval',\n",
    "    'LOAD', 'models/ckpt.48.pth',\n",
    "    'MODEL.BEACON_MODEL', 'models/epoch=04-val_loss=0.4979.ckpt'\n",
    "]\n",
    "\n",
    "config = get_config(config, opts=options)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 21:30:42,257 config: CHECKPOINT_FOLDER: models/eval\n",
      "CHECKPOINT_INTERVAL: 10\n",
      "CUDA: True\n",
      "CUDA_DETERMINISTIC: False\n",
      "DATA:\n",
      "  AUX_MEAN: 0.04\n",
      "  AUX_STD: 0.06\n",
      "DEBUG: False\n",
      "ENV:\n",
      "  ENV_NAME: ThorInteractionCountComparison-v0\n",
      "  FRAME_SIZE: 300\n",
      "  LOCAL_EXE: None\n",
      "  NGRID: 5\n",
      "  NUM_ENV_STEPS: 1000000\n",
      "  NUM_STEPS: 256\n",
      "  OBS_SZ: 128\n",
      "  ROT_SIZE_X: 15\n",
      "  ROT_SIZE_Y: 30\n",
      "EVAL:\n",
      "  DATASET: interaction_exploration/data/test_episodes_K_16.json\n",
      "EVAL_CKPT_NUMBER: -1\n",
      "LOAD: models/ckpt.48.pth\n",
      "LOG_FILE: models/eval/run.log\n",
      "LOG_INTERVAL: 1\n",
      "MODE: train\n",
      "MODEL:\n",
      "  BEACON_MODEL: models/epoch=04-val_loss=0.4979.ckpt\n",
      "  ENCODER: RGBAffordanceTwoStream\n",
      "  TRAINER: BeaconTrainer\n",
      "NUM_PROCESSES: 2\n",
      "NUM_UPDATES: 1953\n",
      "OUT_DIR: \n",
      "RL:\n",
      "  PPO:\n",
      "    clip_param: 0.2\n",
      "    entropy_coef: 0.01\n",
      "    eps: 1e-05\n",
      "    gae_lambda: 0.95\n",
      "    gamma: 0.99\n",
      "    hidden_size: 512\n",
      "    lr: 0.0002\n",
      "    max_grad_norm: 0.5\n",
      "    num_mini_batch: 2\n",
      "    num_steps: 256\n",
      "    policy_wts: \n",
      "    ppo_epoch: 4\n",
      "    reward_window_size: 10\n",
      "    tau: 0.95\n",
      "    use_gae: True\n",
      "    use_linear_clip_decay: False\n",
      "    use_linear_lr_decay: False\n",
      "    use_normalized_advantage: False\n",
      "    value_loss_coef: 0.5\n",
      "SEED: 1\n",
      "TASK_CONFIG:\n",
      "  TASK: None\n",
      "TENSORBOARD_DIR: models/eval/tb/\n",
      "TORCH_GPU_ID: 0\n",
      "X_DISPLAY: :0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet checkpoint loaded\n",
      "Using trainer: <class 'interaction_exploration.trainer.BeaconTrainer'>  | Encoder: <class 'interaction_exploration.models.policy.RGBAffordanceTwoStream'>\n"
     ]
    }
   ],
   "source": [
    "random.seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "\n",
    "trainer = get_trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 21:30:44,416 env config: CHECKPOINT_FOLDER: models/eval\n",
      "CHECKPOINT_INTERVAL: 10\n",
      "CUDA: True\n",
      "CUDA_DETERMINISTIC: False\n",
      "DATA:\n",
      "  AUX_MEAN: 0.04\n",
      "  AUX_STD: 0.06\n",
      "DEBUG: False\n",
      "ENV:\n",
      "  ENV_NAME: ThorInteractionCountComparison-v0\n",
      "  FRAME_SIZE: 300\n",
      "  LOCAL_EXE: None\n",
      "  NGRID: 5\n",
      "  NUM_ENV_STEPS: 1000000\n",
      "  NUM_STEPS: 256\n",
      "  OBS_SZ: 128\n",
      "  ROT_SIZE_X: 15\n",
      "  ROT_SIZE_Y: 30\n",
      "  TEST_EPISODES: ['FloorPlan226', 'FloorPlan227', 'FloorPlan228', 'FloorPlan229', 'FloorPlan230']\n",
      "  TEST_EPISODE_COUNT: 5\n",
      "EVAL:\n",
      "  DATASET: interaction_exploration/data/test_episodes_K_16.json\n",
      "EVAL_CKPT_NUMBER: -1\n",
      "LOAD: models/ckpt.48.pth\n",
      "LOG_FILE: models/eval/run.log\n",
      "LOG_INTERVAL: 1\n",
      "MODE: train\n",
      "MODEL:\n",
      "  BEACON_MODEL: models/epoch=04-val_loss=0.4979.ckpt\n",
      "  ENCODER: RGBAffordanceTwoStream\n",
      "  TRAINER: BeaconTrainer\n",
      "NUM_PROCESSES: 2\n",
      "NUM_UPDATES: 1953\n",
      "OUT_DIR: \n",
      "RL:\n",
      "  PPO:\n",
      "    clip_param: 0.2\n",
      "    entropy_coef: 0.01\n",
      "    eps: 1e-05\n",
      "    gae_lambda: 0.95\n",
      "    gamma: 0.99\n",
      "    hidden_size: 512\n",
      "    lr: 0.0002\n",
      "    max_grad_norm: 0.5\n",
      "    num_mini_batch: 2\n",
      "    num_steps: 256\n",
      "    policy_wts: \n",
      "    ppo_epoch: 4\n",
      "    reward_window_size: 10\n",
      "    tau: 0.95\n",
      "    use_gae: True\n",
      "    use_linear_clip_decay: False\n",
      "    use_linear_lr_decay: False\n",
      "    use_normalized_advantage: False\n",
      "    value_loss_coef: 0.5\n",
      "SEED: 1\n",
      "TASK_CONFIG:\n",
      "  TASK: None\n",
      "TENSORBOARD_DIR: models/eval/tb/\n",
      "TORCH_GPU_ID: 0\n",
      "X_DISPLAY: :0\n"
     ]
    }
   ],
   "source": [
    "trainer.init_viz()\n",
    "test_episodes = ['FloorPlan226', 'FloorPlan227', 'FloorPlan228', 'FloorPlan229', 'FloorPlan230']\n",
    "\n",
    "trainer.config.defrost()\n",
    "trainer.config.ENV.TEST_EPISODES = test_episodes\n",
    "trainer.config.ENV.TEST_EPISODE_COUNT = len(test_episodes)\n",
    "trainer.config.MODE = 'train'\n",
    "trainer.config.freeze()\n",
    "\n",
    "checkpoint_path = trainer.config.LOAD\n",
    "ckpt_dict = trainer.load_checkpoint(checkpoint_path, map_location=\"cpu\")\n",
    "ppo_cfg = trainer.config.RL.PPO\n",
    "\n",
    "logger.info(f\"env config: {trainer.config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.envs = construct_envs(trainer.config, get_env_class(trainer.config.ENV.ENV_NAME))\n",
    "trainer._setup_actor_critic_agent(ppo_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 21:30:48,848 models/ckpt.48.pth\n",
      "2024-03-03 21:30:48,849 num_steps: 256\n"
     ]
    }
   ],
   "source": [
    "logger.info(checkpoint_path)\n",
    "logger.info(f\"num_steps: {trainer.config.ENV.NUM_STEPS}\")\n",
    "\n",
    "trainer.agent.load_state_dict(ckpt_dict[\"state_dict\"])\n",
    "trainer.actor_critic = trainer.agent.actor_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [03:22<00:00, 67.53s/it]\n",
      "2024-03-03 21:34:11,462 Average episode reward: 1.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,463 episode reward Std: 0.8165 (6 episodes)\n",
      "2024-03-03 21:34:11,463 Average episode pickupable_IoU: 0.4928 (6 episodes)\n",
      "2024-03-03 21:34:11,463 episode pickupable_IoU Std: 0.0444 (6 episodes)\n",
      "2024-03-03 21:34:11,464 Average episode pickupable_accuracy: 0.9608 (6 episodes)\n",
      "2024-03-03 21:34:11,464 episode pickupable_accuracy Std: 0.0276 (6 episodes)\n",
      "2024-03-03 21:34:11,464 Average episode pickupable_cohen_kappa: 0.1277 (6 episodes)\n",
      "2024-03-03 21:34:11,464 episode pickupable_cohen_kappa Std: 0.0904 (6 episodes)\n",
      "2024-03-03 21:34:11,465 Average episode pickupable_precision: 0.0948 (6 episodes)\n",
      "2024-03-03 21:34:11,465 episode pickupable_precision Std: 0.0654 (6 episodes)\n",
      "2024-03-03 21:34:11,465 Average episode pickupable_recall: 0.5235 (6 episodes)\n",
      "2024-03-03 21:34:11,466 episode pickupable_recall Std: 0.1949 (6 episodes)\n",
      "2024-03-03 21:34:11,466 Average episode pickupable_f1_score: 0.1443 (6 episodes)\n",
      "2024-03-03 21:34:11,466 episode pickupable_f1_score Std: 0.0980 (6 episodes)\n",
      "2024-03-03 21:34:11,466 Average episode pickupable_true_positive: 205.4668 (6 episodes)\n",
      "2024-03-03 21:34:11,467 episode pickupable_true_positive Std: 138.1381 (6 episodes)\n",
      "2024-03-03 21:34:11,467 Average episode pickupable_true_negative: 52.8438 (6 episodes)\n",
      "2024-03-03 21:34:11,467 episode pickupable_true_negative Std: 34.8002 (6 episodes)\n",
      "2024-03-03 21:34:11,468 Average episode pickupable_false_positive: 205.4668 (6 episodes)\n",
      "2024-03-03 21:34:11,468 episode pickupable_false_positive Std: 138.1381 (6 episodes)\n",
      "2024-03-03 21:34:11,468 Average episode pickupable_false_negative: 52.8438 (6 episodes)\n",
      "2024-03-03 21:34:11,468 episode pickupable_false_negative Std: 34.8002 (6 episodes)\n",
      "2024-03-03 21:34:11,469 Average episode pickupable_object_level_accuracy: 0.7937 (6 episodes)\n",
      "2024-03-03 21:34:11,469 episode pickupable_object_level_accuracy Std: 0.0571 (6 episodes)\n",
      "2024-03-03 21:34:11,471 Average episode moveable_pickupable_IoU: 0.3920 (6 episodes)\n",
      "2024-03-03 21:34:11,471 episode moveable_pickupable_IoU Std: 0.0322 (6 episodes)\n",
      "2024-03-03 21:34:11,471 Average episode moveable_pickupable_accuracy: 0.7841 (6 episodes)\n",
      "2024-03-03 21:34:11,472 episode moveable_pickupable_accuracy Std: 0.0643 (6 episodes)\n",
      "2024-03-03 21:34:11,472 Average episode moveable_pickupable_cohen_kappa: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,472 episode moveable_pickupable_cohen_kappa Std: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,473 Average episode moveable_pickupable_precision: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,474 episode moveable_pickupable_precision Std: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,474 Average episode moveable_pickupable_recall: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,475 episode moveable_pickupable_recall Std: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,475 Average episode moveable_pickupable_f1_score: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,476 episode moveable_pickupable_f1_score Std: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,476 Average episode moveable_pickupable_true_positive: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,477 episode moveable_pickupable_true_positive Std: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,477 Average episode moveable_pickupable_true_negative: 3537.7194 (6 episodes)\n",
      "2024-03-03 21:34:11,478 episode moveable_pickupable_true_negative Std: 1053.5169 (6 episodes)\n",
      "2024-03-03 21:34:11,478 Average episode moveable_pickupable_false_positive: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,479 episode moveable_pickupable_false_positive Std: 0.0000 (6 episodes)\n",
      "2024-03-03 21:34:11,480 Average episode moveable_pickupable_false_negative: 3537.7194 (6 episodes)\n",
      "2024-03-03 21:34:11,480 episode moveable_pickupable_false_negative Std: 1053.5169 (6 episodes)\n",
      "2024-03-03 21:34:11,481 Average episode moveable_pickupable_object_level_accuracy: 0.5472 (6 episodes)\n",
      "2024-03-03 21:34:11,481 episode moveable_pickupable_object_level_accuracy Std: 0.0620 (6 episodes)\n"
     ]
    }
   ],
   "source": [
    "results = execute_evaluation(trainer, ppo_cfg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{config.CHECKPOINT_FOLDER}/results.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile, indent=4, sort_keys=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facebook-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
